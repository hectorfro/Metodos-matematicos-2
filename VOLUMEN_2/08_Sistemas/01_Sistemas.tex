\section{Algunos comentarios iniciales}

Cuando consideramos la evolución de sistemas con varios grados de libertad
o con varias partículas, naturalmente arribamos al tratamiento de sistemas
de ecuaciones diferenciales. En estos sistemas encontramos varias variables
dependientes de una sola variable independiente. El más natural de los
ejemplos es el caso de un sistema de partículas que se mueve en el espacio
bajo la acción de fuerzas externas:

\begin{eqnarray*}
{\mathbf F}_{1}\left(  r_{1}\left(  t\right)  ,r_{2}\left(  t\right),\cdots , 
r_{n}\left(  t\right)  ,\frac{\mathrm{d} r_{1}\left(  t\right)  }
{\mathrm{d}t},\frac{\mathrm{d}r_{2}\left(  t\right)}{\mathrm{d}t}, \cdots, 
\frac{\mathrm{d}r_{n}\left(  t\right)  }{\mathrm{d}t},t\right)   &
=\dfrac{\mathrm{d}^{2}r_{1}\left(  t\right)  }{\mathrm{d}t^{2}}\\
{\mathbf F}_{2}\left(  r_{1}\left(  t\right)  ,r_{2}\left(  t\right),\cdots , 
r_{n}\left(  t\right)  ,\frac{\mathrm{d} r_{1}\left(  t\right)  }
{\mathrm{d}t},\frac{\mathrm{d}r_{2}\left(  t\right)}{\mathrm{d}t}, \cdots, 
\frac{\mathrm{d}r_{n}\left(  t\right)  }{\mathrm{d}t},t\right)   &
=\dfrac{\mathrm{d}^{2}r_{2}\left(  t\right)  }{\mathrm{d}t^{2}}\\
\vdots \qquad \qquad \qquad \qquad \qquad \qquad \qquad \qquad &  \vdots \\
{\mathbf F}_{n}\left(  r_{1}\left(  t\right)  ,r_{2}\left(  t\right),\cdots , 
r_{n}\left(  t\right)  ,\frac{\mathrm{d} r_{1}\left(  t\right)  }
{\mathrm{d}t},\frac{\mathrm{d}r_{2}\left(  t\right)}{\mathrm{d}t}, \cdots, 
\frac{\mathrm{d}r_{n}\left(  t\right)  }{\mathrm{d}t},t\right)   &
=\dfrac{\mathrm{d}^{2}r_{n}\left(  t\right)  }{\mathrm{d}t^{2}}
\end{eqnarray*}

Por otro lado, es importante acotar de que existe la posibilidad de convertir 
una ecuación diferencial ordinaria de orden superior es un sistema equivalente 
de ecuaciones diferenciales. Es decir, dada una ecuación diferencial de la forma
\[
y^{\left(n\right)  }\left(  x\right)  =\mathrm{F}\left(y^{\left(
n-1\right)  }\left(  x\right), y^{\left(  n-2\right)  }\left(  x\right)
,,\cdots y'''\left(  x\right)  ,y''\left(  x\right)  ,y'\left(x\right)  ,y\left(  x\right)  ,x\right)
\]
si hacemos el siguiente cambio variable

\[
u_{n}=y^{\left(  n-1\right)  }\left( x\right)  ;\quad u_{n-1}=y^{\left(n-2\right)  }\left(  x\right);
\quad \cdots \quad u_{4}=y''' \left(  x\right)
;\quad u_{3}=y'' \left(  x\right)  ;\quad u_{2}=y'\left(  x\right)
;\quad u_{1}=y\left(  x\right)
\]
entonces construir el siguiente sistema de ecuaciones diferenciales
\begin{align*}
u'_{n}(x)  &  =\mathrm{F}_{n}\left( u_{n}, u_{n-1}, \cdots, u_{3}, u_{2}, u_{1}, x \right) \\
u'_{n-1}(x)  &  =y^{\left(  n-1\right)  }\left(  x\right) \\
&  \vdots\\
u'_{3}(x)   &  =y''' \left(  x\right) \\
u'_{2}(x)   &  =y''  \left(  x\right) \\
u'_{1}(x)   &  =y'   \left(  x\right)
\end{align*}
que puede ser generalizado a:
\begin{align*}
u'_{n}(x)   &  =\mathrm{F}_{n}\left(u_{n}, u_{n-1},\cdots, u_{4}, u_{3}, u_{2}, u_{1}, x\right) \\
u'_{n-1}(x)   &  =\mathrm{F}_{n-1}\left(u_{n}, u_{n-1},\cdots, u_{4}, u_{3}, u_{2}, u_{1}, x\right) \\
&  \vdots  \qquad  \qquad   \qquad  \qquad  \vdots  \\ 
u'_{2}(x)  &  =\mathrm{F}_{2}\left(u_{n}, u_{n-1},\cdots, u_{4}, u_{3}, u_{2}, u_{1}, x \right) \\
u'_{1}(x)   &  =\mathrm{F}_{1}\left(u_{n}, u_{n-1},\cdots, u_{4}, u_{3}, u_{2}, u_{1}, x\right)
\end{align*}

Para garantizar que existe solución al problema de valores iniciales se
debe imponer algunas restricciones sobre las funciones $\mathrm{F}_{i}\left(
u_{n},\cdots,u_{3},u_{2},u_{1},t\right)  $ para ello existen un par de
teoremas que garantice esa solución

\begin{mdframed}[linecolor=OliveGreen,linewidth=0.3mm]
\textbf{Teorema}: Sean las funciones $\mathrm{F}_{1},\mathrm{F}
_{2},\cdots\mathrm{F}_{n}$ y sus derivadas:
\[\partial_{1}
\mathrm{F}_{1},\partial_{1}\mathrm{F}_{2},\cdots\partial_{1}\mathrm{F}
_{n},\cdots\partial_{i}\mathrm{F}_{1},\partial_{i}\mathrm{F}_{2}
,\cdots\partial_{j}\mathrm{F}_{n}\cdots\partial_{n}\mathrm{F}_{1},\partial
_{n}\mathrm{F}_{2},\cdots\partial_{n}\mathrm{F}_{n}
\]
continuas en una región \emph{R} del espacio $\left(x, u_{1}, u_{2},\cdots ,  u_{n}\right)$, 
 que contiene al punto $\left(x_{0}, u_{1}^{0}, u_{2}^{0},\cdots , u_{n}^{0}\right)$ 
 que caracteriza las condiciones iniciales. Entonces existe un
intervalo $|  x-x_{0}|  <h$ en el cual existe una única
solución: $\ u_{1}=\phi_{1}\left( x\right)  ,u_{2}=\phi_{2}\left(x\right)  ,\cdots, u_{n}=
\phi_{n}\left(x\right)$. 
\end{mdframed}

Hemos denotado
$\partial_{j}\mathrm{F}_{i}=\dfrac{\partial\mathrm{F}_{i}}{\partial u_{j}}$ y 
$u_{m}^{0}=u_{m}\left(x_{0}\right)$ las condiciones iniciales.

\begin{mdframed}[linecolor=OliveGreen,linewidth=0.3mm]
\textbf{Teorema}: Sea el siguiente sistema lineal de ecuaciones diferenciales
\begin{eqnarray}
u'_{1}  & = &p_{11}\left(x\right)  \ u_{1}+p_{12}\left(x\right) \ u_{2}+\cdots + p_{1n}\left(x\right)  \ u_{n}+g_{1}\left(x\right)  \nonumber \\
u'_{2}  &  = &p_{21}\left(x\right)  \ u_{1}+p_{22}\left(x\right)\ u_{2}+\cdots + p_{2n}\left(x\right)  \ u_{n}+g_{2}\left(x\right) \nonumber  \\
 &  \vdots &    \qquad  \qquad   \qquad  \qquad  \vdots \nonumber \\
u'_{n}  &  = &p_{n1}\left(x\right)  \ u_{1}+p_{n2}\left(x\right)\ u_{2}+\cdots +p_{nn}\left(x\right)  \ u_{n}+g_{n}\left(x\right) 
\label{elsistema}
\end{eqnarray}
Si $p_{11}\left(x\right)  ,p_{12}\left( x\right)  ,\cdots p_{1n}\left(x\right)  \cdots p_{ij}\left(x\right)  \cdots$ 
$p_{nn}\left(x\right)  $ y
$g_{1}\left(x\right)  \cdots g_{n}\left(x\right)  $ son funciones continua
en el intervalo $\alpha<x<\beta$ que contiene al punto $x=x_{0}$ entonces
existe una única solución que satisface las condiciones iniciales
$u_{m}^{0}=u_{m}\left(x_{0}\right)$. 
\end{mdframed}

Por ejemplo: dada la siguiente ecuación diferencial de tercer orden, no lineal
\[
y''' = 3xy' - y^2y''\,, \qquad \text{con:}\quad y(0)=1, \, y'(0)=-1, \, y''(0)=2\,,
\]

Por el hecho de ser no lineal, los métodos anteriormente vistos no pueden ser aplicados aquí. Pero 
podemos construir un sistema de ecuaciones diferenciales equivalente a la ecuación anterior.  
Consideramos que $y(x)$ es una solución de la ecuación diferencial dada y definamos  las
siguientes cantidades:
\begin{eqnarray*}
y(x)  &  =& u_1(x) \\
y'(x)  & = & u'_1(x)= u_2(x)\\
y''(x)  & = & u''_1(x)= u'_2(x)=u_3(x) \\
y'''(x)  & = & u'''_1(x)= u''_2(x)=u'_3(x)
\end{eqnarray*}
por lo tanto, la ecuación diferencial dada se puede escribir como:
\[
y''' = 3xy' - y^2y'' \quad \Rightarrow \quad u'_3 = 3xu_2 - u_1^2u_3\,,
\]
ahora, el sistema de ecuaciones de primer orden equivalente a la ecuación diferencial problema es:
\begin{align*}
u'_1(x)  & = u_2(x)\\
u'_2(x)  &=  u_3(x) \\
u'_3(x)  & = 3xu_2 - u_1^2u_3
\end{align*}
que debemos resolver para el conjunto de condiciones iniciales: 
\[
u_1(0)=y(0)=1, \, u_2(0)=y'(0)=-1, \, u_3(0)=y''(0)=2 \,,
\]
por lo tanto, la función $u_1(x)$ que satisface éste último sistema será la solución de la ecuación diferencial de nuestro problema.
Es necesario entonces tener la capacidad de resolver sistemas de ecuaciones diferenciales de primer orden y a este cometido nos dedicaremos a continuación. 

\subsection{Notación matricial} 

El sistema lineal antes mencionado, es decir, las ecuaciones (\ref{elsistema}), puede condensarse en la siguiente ecuación matricial
\begin{equation}
\mathbf{u}'(x)=\mathbf{P}\left(x\right)  \mathbf{u}(x)+\mathbf{g}\left(x\right)  \,,
\label{sismatrix}
\end{equation}
en la cual estamos representando
\[
\mathbf{u}'=\left(
\begin{array}
[c]{c}
u'_{1}(x)\\
u'_{2}(x)\\
\vdots\\
u'_{n}(x)
\end{array}
\right) ; \,\, \mathbf{P}  =\left(
\begin{array}
[c]{cccc}
p_{11}\left(x\right)  & p_{12}\left(x\right)  & \cdots &  p_{1n}\left(x\right) \\
p_{21}\left(x\right)  & p_{22}\left(x\right)  & \cdots &  p_{2n}\left(x\right) \\
\vdots & \vdots & \ddots & \vdots\\
p_{n1}\left(x\right)  & p_{n2}\left(x\right)  & \cdots &  p_{nn}\left(x\right)
\end{array}
\right)  ; \,\, \mathbf{u}=\left(
\begin{array}
[c]{c}
u_{1}(x)\\
u_{2}(x)\\
\vdots\\
u_{n}(x)
\end{array}
\right) ; \,\,  \mathbf{g} =\left(
\begin{array}
[c]{c}
g_{1}\left(x\right) \\
g_{2}\left(x\right) \\
\vdots\\
g_{n}\left(x\right)
\end{array}
\right)
\]

El sistema (\ref{sismatrix}) será homogéneo si $\mathbf{g}\left(x\right)=0$, en caso contrario será un sistema no homogéneo.

\subsection{Sistemas lineales homogéneos}
Dado un sistema de ecuaciones diferenciales con coeficientes constantes, es decir,  de la
forma
 \begin{equation}
\mathbf{y}'(x)=\mathbf{Ay}(x) \,,
\label{sishomo}
\end{equation}
procedemos de manera análoga al caso de una sola ecuación con coeficientes constantes. 

Se considera una  solución de prueba de la forma:
$\mathbf{y}= {\boldsymbol \xi}{e}^{rx}$, donde $r$ y el vector constante ${\boldsymbol \xi }$ son elementos a determinar. Al sustituir esta solución en (\ref{sishomo}), obtenemos:
${ \boldsymbol \xi}r {e}^{rx}= \mathbf{A}{\boldsymbol \xi }{e}^{rx}$, con lo cual, el problema se reduce a la búsqueda de los autovalores y autovectores del sistema $\mathbf{A}{\boldsymbol \xi}=r{\boldsymbol \xi}$.

En forma de matrices, la ecuación (\ref{sishomo}) es:
\[
\left(
\begin{array}
[c]{c}
y'_{1}\\
y'_{2}\\
\vdots\\
y'_{n}
\end{array}
\right)  =\left(
\begin{array}
[c]{cccc}
a_{11} & a_{12} & \cdots &  a_{1n}\\
a_{21} & a_{22} & \cdots &  a_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
a_{n1} & a_{n2} & \cdots &  a_{nn}
\end{array}
\right)  \ \left(
\begin{array}
[c]{c}
y_{1}\\
y_{2}\\
\vdots\\
y_{n}
\end{array}
\right)  \quad\Rightarrow\quad\left(
\begin{array}
[c]{c}
y_{1}\left( x\right) \\
y_{2}\left( x\right) \\
\vdots\\
y_{n}\left( x\right)
\end{array}
\right)  ={\large e}^{r x}\left(
\begin{array}
[c]{c}
\xi_{1}\\
\xi_{2}\\
\vdots\\
\xi_{n}
\end{array}
\right)
\]
con $a_{ij}$, y $\xi_{i}$ como constantes. 

Por lo tanto:
\[
\mathbf{A}{\boldsymbol \xi}=r{\boldsymbol \xi} \quad \Rightarrow \quad \left(  \mathbf{A}-r \mathbf{I} \right)  \mathbf{\xi=0}\,,
\]
en forma de matrices, esto es:
\begin{equation}
\left(
\begin{array}
[c]{cccc}
a_{11}-r & a_{12} & \cdots &  a_{1n}\\
a_{21} & a_{22}-r & \cdots &  a_{2n}\\
\vdots & \vdots & \ddots & \vdots\\
a_{n1} & a_{n2} & \cdots &  a_{nn}-r
\end{array}
\right)  \left(
\begin{array}
[c]{c}
\xi_{1}\\
\xi_{2}\\
\vdots\\
\xi_{n}
\end{array}
\right)  =\left(
\begin{array}
[c]{c}
0\\
0\\
\vdots\\
0
\end{array}
\right)
\label{sismathom}
\end{equation}

Es decir, para resolver el sistema de ecuaciones diferenciales lineales con coeficientes constantes, es necesario resolver el sistema de ecuaciones algebraico. 

Por ejemplo,  resolvamos el siguiente sistema de ecuaciones 
\begin{align*}
y'_1(x)  & = y_1(x)+ y_2(x)\\
y'_2(x)  & = 4y_1(x)+ y_2(x)
\end{align*}
este sistema se puede representar de la siguiente forma
\[
\mathbf{y}'=\left(
\begin{array}
[c]{cc}
1 & 1\\
4 & 1
\end{array}
\right)  \mathbf{y}\qquad\text{si}\quad \mathbf{y}={\boldsymbol \xi} 
{e}^{rx} \quad \Rightarrow\quad\left(
\begin{array}
[c]{cc}
1-r & 1\\
4 & 1-r
\end{array}
\right)  \left(
\begin{array}
[c]{c}
\xi_{1}\\
\xi_{2}
\end{array}
\right)  =\left(
\begin{array}
[c]{c}
0\\
0
\end{array}
\right)
\]
primero que todo se calculan los autovalores:
\[
\left|
\begin{array}
[c]{cc}
1-r & 1\\
4 & 1-r
\end{array}
\right|  =\left(  1-r\right)  ^{2}-4=r^{2}-2r-3=0\quad  \Rightarrow
\quad\left\{
\begin{array}
[l]{l}
r_{1}=3\\
\\
r_{2}=-1
\end{array}
\right.
\]
para el autovalor $r_1=3$, (\ref{sismathom}) resulta en
\[
-2\mathbf{\ }\xi_{1}^{\left(  1\right)  }
+\xi_{2}^{\left(  1\right)  }=0\quad \Rightarrow\quad {\boldsymbol \xi}^{\left(1\right)  }=
\left(
\begin{array}
[c]{c}
\xi_{1}^{\left(  1\right)  }\\
2\xi_{1}^{\left(  1\right)  }
\end{array}
\right)=
\left(
\begin{array}
[c]{c}
1  \\
2 
\end{array}
\right)
\]
similarmente, para el segundo autovalor  $r_2=-1$, se tiene
\[
{\boldsymbol \xi}^{\left(  2\right)  } = \left(
\begin{array}
[r]{r}
\xi_{1}^{\left(  2\right)  }\\
-2\xi_{1}^{\left(  2\right)  }
\end{array}
\right) =
\left(
\begin{array}
[r]{r}
1  \\
-2 
\end{array}
\right) 
\]
por lo tanto, la solución general del sistema será
\[
\mathbf{y}=C_{1}\ \mathbf{y}^{\left(  1\right) }\left(x\right)
+C_{2}\ \mathbf{y}^{\left(  2\right)  }\left(x\right)  \quad
\Longleftrightarrow\quad\left(
\begin{array}
[c]{c}
y_{1}\\
y_{2}
\end{array}
\right) =  C_{1}\left(
\begin{array}
[c]{c}
1\\
2
\end{array}
\right)  {\large e}^{3x}+C_{2}\left(
\begin{array}
[r]{r}
1\\
-2
\end{array}
\right)  {\large e}^{-x}
\]
Obviamente el wronskiano de esta solución
\[
\mathrm{W}\left[  \mathbf{y}^{\left(  1\right)  }\left(x\right)
,\mathbf{y}^{\left(  2\right)  }\left(x\right)  \right] 
=\left|
\begin{array}
[c]{cc}
{\large e}^{3x} & {\large e}^{-x}\\
2{\large e}^{3x} & -2{\large e}^{-x}
\end{array}
\right|  =-4{\large e}^{-2x}\neq0
\]
garantiza que las dos soluciones son linealmente independientes.

Para el caso de matrices hermíticas, $\mathbf{A=A}^{\dagger}$, vale decir, que la matriz $\mathbf{A}$ coincide con su conjugada y traspuesta, $\mathbf{A=}{\left(  \mathbf{A}^{T}\right)^*  }$, todos los autovalores son reales y la solución general para un sistema de $n$ ecuaciones diferenciales lineales con coeficientes constantes es
\[
\mathbf{y}\left(x\right)  = C_{1}\ {\boldsymbol \xi}^{\left(  1\right)}{ e}^{r_{1} x }+
C_{2}\ {\boldsymbol \xi}^{\left(  2\right)  }{e}^{r_{2} x }+\cdots+
C_{n}\ {\boldsymbol \xi}^{\left(  n\right)  }{e}^{r_{n} x} \,.
\]

Para el caso particular de matrices simétricas (hermíticas reales) los autovalores $r_{1}, r_{2}, \cdots , \ r_{n}$ y los autovectores ${\boldsymbol \xi}^{\left(  1\right)}, {\boldsymbol \xi}^{\left(  2\right)  }, \cdots ,  {\boldsymbol \xi}^{\left(  n\right)  }$ resultan ser ambos  reales.

Consideremos ahora el caso cuando la matrix $\mathbf{A}$ no es hermítica pero  real. Entonces
\[
\mathbf{y}'=\mathbf{A y} \,\, \Rightarrow \,\, 
\mathbf{y} =  {\boldsymbol \xi} {e}^{r x} \,\, \Rightarrow \,\, 
\left(  \mathbf{A}-r \mathbf{I}\right) {\boldsymbol \xi}= \mathbf{0} \,\, \Rightarrow \,\,
\left\{
\begin{array}
[c]{c}
r_{1}=\lambda+ i \mu\\
\\
r_{2}=\lambda-i \mu
\end{array}
\right.  
\]
esto significa que $r_{1}=r_{2}^{*}$ y que ${\boldsymbol \xi}^{\left(1\right)  }=\left({\boldsymbol \xi}^{\left(2\right)}\right)^*$, por lo cual ${\boldsymbol \xi}^{\left(1\right)  }=\mathbf{a} + i\mathbf{b}$ con $\mathbf{a}$ y $\mathbf{b}$ vectores reales, entonces:
\begin{eqnarray*}
\mathbf{y}^{(1)}(x)   &  =& \left(  \mathbf{a} + i \mathbf{b}\right) 
 {e}^{\left(  \lambda+i\mu\right)x} = \left(  \mathbf{a}+i\mathbf{b}\right)  
 {e}^{\lambda x}\left[  \cos(\mu x)+  i\ \text{sen}  (\mu x) \right] \\
 &  =&{{e}^{\lambda x}\left[  \mathbf{a}\cos(\mu x) -\mathbf{b} \ {\text{sen}}(\mu x)\right]}+
{i} {{e}^{\lambda x}\left[  \mathbf{a}\ {\text{sen}}(\mu x)+\mathbf{b}\cos(\mu x) \right]  }\\
&  =& \mathbf{u}\left(x\right)  +{i}\mathbf{v}\left(x\right)\,. 
\end{eqnarray*}

Es posible que se nos presente la siguiente situación:  por un lado, algunos de  los autovalores de la matriz real, $\mathbf{A}$, son números complejos, $r_{1}=\lambda+ i \mu$ y $r_{2}=\lambda-{i}\mu$, pero el resto de las raíces resultan ser  números reales: $r_{3}, r_{4}, \cdots , \ r_{n}$. Por el otro lado, algunos de los autovectores  son complejos: ${\boldsymbol \xi}^{\left(1\right)  }=\mathbf{a}+{i}\mathbf{b}$, ${\boldsymbol \xi}^{\left(2\right)}=\mathbf{a}-{i}\mathbf{b}$, pero el resto de autovectores no lo son: ${\boldsymbol \xi}^{\left(  3\right)  }, {\boldsymbol \xi}^{\left(  4\right)}, \cdots , {\boldsymbol \xi}^{\left(  n\right)}$.

En este caso, la solución general sera
\[
\mathbf{y}\left( x\right)  =C_{1}\mathbf{u}\left(x\right)  +{i} C_{2}\mathbf{v}\left(x\right)  +
C_{3} {\boldsymbol \xi}^{\left(3\right)}{e}^{r_{3}x}+C_{4}{\boldsymbol \xi}^{\left(4\right)  }{e}^{r_{4}x}+\cdots+
C_{n}{\boldsymbol \xi}^{\left(n\right)  }{e}^{r_{n}x}\,.
\]

Queremos resolver el siguiente sistema de ecuaciones
\begin{align*}
y'_1(x)  & = y_1(x)- y_2(x)\\
y'_2(x)  & = 5 y_1(x) -3 y_2(x)
\end{align*}
En forma de matrices lo que tenemos es
\[
\mathbf{y}'= \mathbf{A y} \,\, \Rightarrow \,\, 
\mathbf{y}'=\left(
\begin{array}
[c]{cc}
1 & -1\\
5 & -3
\end{array}
\right)  \mathbf{y} 
\]
Si utilizamos la siguiente solución de prueba $\mathbf{y}={\boldsymbol \xi}{e}^{rx}$ , entonces:
\[
\left(
\begin{array}
[c]{cc}
1-r & -1\\
5 & -3-r
\end{array}
\right)  \left(
\begin{array}
[c]{c}
\xi_{1}\\
\xi_{2}
\end{array}
\right)  =\left(
\begin{array}
[c]{c}
0\\
0
\end{array}
\right)
\]
Se calculan los autovalores
\[
\left|
\begin{array}
[c]{cc}
1-r & -1\\
5 & -3-r
\end{array}
\right|  =r^{2}+2r+2=0\,\, \Rightarrow \,\, \left\{
\begin{array}
[c]{c}
r_{1}=-1+{i}\\
\\
r_{2}=-1-{i}
\end{array}
\right. \,\, \Rightarrow \,\, \left\{
\begin{array}
[c]{c}
{\boldsymbol \xi}^{\left(  1\right)  }=\left(
\begin{array}
[c]{c}
1\\
2-{i}
\end{array}
\right) \\
\\
{\boldsymbol \xi}^{\left(  2\right)  }=\left(
\begin{array}
[c]{c}
1\\
2+{i}
\end{array}
\right)
\end{array}
\right.
\]
finalmente la solución general será
\[
\mathbf{y}(x)  =C_{1}\ {e}^{-x}
\left(
\begin{array}
[c]{c}
\cos(x)\\
2\cos(x) +\text{sen}(x)
\end{array}
\right)  + {i} C_{2}\ {e}^{-x}\left(
\begin{array}
[c]{c}
\text{sen}(x)\\
-\cos(x)+2\text{sen}(x)
\end{array}
\right)\,.
\]

En el caso que los autovalores de la matriz real, $\mathbf{A}$, estén repetidos $k$ veces, es decir: $r_{1}=r_{2}= \cdots =r_{k}=\rho$,  y para los restantes  $r_{k+1}, \dots , r_{n}$ distintos, se debe considerar algunos puntos. Lo primero es notar que puede suceder que existan ${\boldsymbol \xi}^{(1)}, {\boldsymbol \xi}^{(2)}, \dots , {\boldsymbol \xi}^{(k)}$ autovectores linealmente  independientes asociados al autovalor $\rho$ de multiplicidad $k$. Entonces, el conjunto de vectores linealmente independientes siguientes: $\mathbf{y}^{(1)}(x)={\boldsymbol \xi}^{(1)}e^{\rho x}, \mathbf{y}^{(2)}(x)={\boldsymbol \xi}^{(2)}e^{\rho x}, \dots , \mathbf{y}^{(k)}(x)={\boldsymbol \xi}^{(k)}e^{\rho x}$ serán soluciones del sistema de ecuaciones diferenciales (\ref{sishomo}). Pero si la matrix $\mathbf{A}$ no es hermítica  existirá un número menor de autovectores correspondientes al autovalor $\rho$ de multiplicidad $k$ y no será posible tener entonces las $k$ soluciones necesarias del sistema (\ref{sishomo}). Por lo tanto, se necesitará  construir las soluciones que falten de alguna manera. 

Quizás sea conveniente detenerse en un  ejemplo particular. Dado el sistema:
\begin{align*}
y'_1(x)  & = y_1(x)- y_2(x)\\
y'_2(x)  & =  y_1(x) +3 y_2(x) \,,
\end{align*}
por lo tanto
\[
\mathbf{y}'= \mathbf{A y} \quad \Rightarrow \quad 
\mathbf{y}'=\left(
\begin{array}
[c]{cc}
1 & -1\\
1 & 3
\end{array}
\right)  \mathbf{y} \,.
\]

Si repetimos el procedimiento anterior, se tiene que
\[
\left(
\begin{array}
[c]{cc}
1-r & -1\\
1 & 3-r
\end{array}
\right)  \left(
\begin{array}
[c]{c}
\xi_{1}\\
\xi_{2}
\end{array}
\right)  =\left(
\begin{array}
[c]{c}
0\\
0
\end{array}
\right) \,,
\]
calculamos los autovalores:  
\[
\left|
\begin{array}
[c]{cc}
1-r & -1\\
1 & 3-r
\end{array}
\right|  = r^{2}-4r+4=(r-2)^2=0 \,\, \Rightarrow \,\,  \left\{
\begin{array}
[c]{c}
r_{1}=2\\
\\
r_{2}=2
\end{array}
\right.  \Rightarrow\quad 
{\boldsymbol \xi}^{\left(  1\right)  }=
\left(
\begin{array}
[c]{r}
1\\
-1
\end{array}
\right) \,,
\]
y podemos ver que la multiplicidad es $2$ y sólo podemos obtener un único autovector asociado al autovalor $\rho= r_{1}=r_{2}=2$. Con este autovector podemos construir una solución linealmente independiente:
\[
\mathbf{y}^{(1)}(x)  ={e}^{2x}
\left(
\begin{array}
[c]{r}
1\\
-1
\end{array}
\right)  \,.
\]

Resulta natural intentar buscar una segunda solución que contenga los términos 
$x{e}^{2x}$ y ${e}^{2x}$. 

Propongamos entonces la siguiente solución de prueba
\[
\mathbf{y}^{(2)}(x) ={\boldsymbol \zeta}^{(1)} x {e}^{2x} + {\boldsymbol \zeta}^{(2)}{e}^{2x} \,, 
\]
donde ${\boldsymbol \zeta}^{(1)}$  y ${\boldsymbol \zeta}^{(2)}$ son vectores constantes a determinar.  

Al sustituir esta solución de prueba en nuestra ecuación problema, resulta:
\begin{eqnarray*}
2{\boldsymbol \zeta}^{(1)}x{e}^{2x} + \left({\boldsymbol \zeta}^{(1)}+2{\boldsymbol \zeta}^{(2)}\right){e}^{2x} &=& 
 \mathbf{A}\left({\boldsymbol \zeta}^{(1)} x {e}^{2x} + {\boldsymbol \zeta}^{(2)}{e}^{2x}\right)\,, \\
\left( 2\mathbf{I} - \mathbf{A} \right) {\boldsymbol \zeta}^{(1)}  x {e}^{2x} + 
\left({\boldsymbol \zeta}^{(1)}+2{\boldsymbol \zeta}^{(2)}- \mathbf{A}{\boldsymbol \zeta}^{(2)} \right){e}^{2x} 
 &=& \mathbf{0} \,.
\end{eqnarray*}

Al igualar los coeficientes de los términos $x{e}^{2x}$ y ${e}^{2x}$ en ésta última expresión tenemos el siguiente par de ecuaciones de autovalores:
\begin{eqnarray*}
(\mathbf{A}-2\mathbf{I}) {\boldsymbol \zeta}^{(1)}  &=& \mathbf{0} \\
(\mathbf{A}-2\mathbf{I}) {\boldsymbol \zeta}^{(2)}  &=& {\boldsymbol \zeta}^{(1)} 
\end{eqnarray*}

La primera ecuación es satisfecha si hacemos coincidir $ {\boldsymbol \zeta}^{(1)} =  {\boldsymbol \xi}^{(1)}$, es decir, con el autovector correspondiente a $\rho=2$ que calculamos anteriormente. Por otro lado, se tiene que 
\[
|\mathbf{A}-2\mathbf{I}| =
\left|
\begin{array}
[c]{rr}
-1 & -1\\
1 & 1
\end{array}
\right|  = 0 \,,
\]
pero sin embargo, la segunda ecuación tiene solución
\[ 
\left(
\begin{array}
[c]{rr}
-1 & -1\\
1 & 1
\end{array}
\right)  \left(
\begin{array}
[c]{r}
\zeta^{(2)}_1 \\
\zeta^{(2)}_2 
\end{array}
\right)
 = 
\left(
\begin{array}
[c]{r}
1 \\
-1 
\end{array}
\right) \,.
\]

Como las filas son proporcionales, entonces resulta que:
\[
-\zeta^{(2)}_1-\zeta^{(2)}_2=1 \,\, \Rightarrow \,\, 
{\boldsymbol \zeta}^{(2)}=
\left(
\begin{array}
[c]{r}
0 \\
-1 
\end{array}
\right) +
\kappa \left(
\begin{array}
[c]{r}
1 \\
-1 
\end{array}
\right)
\]
donde $\kappa$ es un valor arbitrario. Hemos construido así una segunda solución
\[
\mathbf{y}^{(2)}(x)  = 
\left(
\begin{array}
[c]{r}
1 \\
-1 
\end{array}
\right) x {e}^{2x} +
\left(
\begin{array}
[c]{r}
0 \\
-1 
\end{array}
\right){e}^{2x} +
\kappa \left(
\begin{array}
[c]{r}
1 \\
-1 
\end{array}
\right) {e}^{2x} \,, 
\]
notemos que el último término de la ecuación anterior es un múltiplo del único término 
de $\mathbf{y}^{(1)}(x)$, por lo tanto debe ser ignorado. 

En resumen, las dos soluciones linealmente independientes son:
\begin{eqnarray*}
\mathbf{y}^{(1)}(x)  &= &{e}^{2x}
\left(
\begin{array}
[c]{r}
1\\
-1
\end{array}
\right) \,, \\
\mathbf{y}^{(2)}(x)  &=& 
\left(
\begin{array}
[c]{r}
1 \\
-1 
\end{array}
\right) x {e}^{2x} +
\left(
\begin{array}
[c]{r}
0 \\
-1 
\end{array}
\right){e}^{2x}  \,, 
\end{eqnarray*}

Se deja como ejercicio demostrar que $W\left[\mathbf{y}^{(1)}(x), \mathbf{y}^{(2)}(x)  \right] \neq 0$. 

La solución general, será entonces
\[
\mathbf{y}(x)= C_1 
\left(
\begin{array}
[c]{r}
1\\
-1
\end{array}
\right)  {e}^{2x}
+ C_2 \left[ 
\left(
\begin{array}
[c]{r}
1 \\
-1 
\end{array}
\right) x {e}^{2x} +
\left(
\begin{array}
[c]{r}
0 \\
-1 
\end{array}
\right){e}^{2x} 
\right]\,.
\]


\subsection{Sistemas lineales inhomogéneos}

Todo operador lineal hermítico $\mathbf{A}$ $(\mathbf{A}:V\rightarrow V)$, con $n$ autovectores distintos  tiene una representación matricial diagonal $\hat{A}_{ij}\mathbf{=}\lambda_{i}\delta_{ij}$.  Mediante una transformación de similidaridad: $\mathbf{TAT}^{-1}=\mathbf{\hat{A}}$, donde $\mathbf{T}$ es una matriz unitaria: $\mathbf{T}^{-1}=\mathbf{T}^{\dagger}$, se trasforma la base de $\mathbf{A}$ a la base donde $\mathbf{\hat{A}}$ es diagonal. 

Este teorema es claro: a partir de que sí $\mathbf{A}$ tiene $n$ autovalores distintos, tiene $n$ autovectores linealmente independientes los cuales forman una base de $V$ y en la cual la representación matricial de $\mathbf{A}$ es diagonal. Pero como siempre es posible pasar de $\mathbf{A}$ no diagonal a $\mathbf{\hat{A}}$  diagonal con los mismos autovalores mediante una transformación de similidaridad $\mathbf{TAT}^{-1}=\mathbf{\hat{A}}$, esto queda demostrado.  Lo anterior puede formalizarse de la siguiente manera:
\[
\left\langle v_{i}\right|  \underset{\mathbf{1}}{\underbrace{\mathbf{T}^{\dagger}\mathbf{T}}}
\mathbf{A}\underset{\mathbf{1}}{\underbrace{\mathbf{T}^{ \dagger}\mathbf{T}}}\left|  v_{j}\right\rangle=\underset{\left\langle u_{i}\right|  }{\underbrace{\left\langle v_{i}\right|\mathbf{T}^{\dagger}}} \underset{\mathbf{\hat{A}}}{\underbrace{\mathbf{TAT}^{\dagger}}}\underset{\left|  u_{j}\right\rangle}{\underbrace{\mathbf{T}\left|  v_{j}\right\rangle }}=\left\langle u_{i}\right|  \mathbf{\hat{A}}\left|  u_{j}\right\rangle =\lambda_{j}\left\langle u_{i}\right.  \left|  u_{j}\right\rangle =\lambda_{j}\delta_{ij}\,.
\]

Nos queda determinar la forma de la matriz unitaria de transformación $\mathbf{T}$. Para ello seleccionamos la base canónica $\left\{  \left| e_{1}\right\rangle ,\left|  e_{2}\right\rangle ,\dots , \left|  e_{i} \right\rangle,  \dots ,  \left|  e_{n}\right\rangle \right\}  $ como base de partida de $\mathbf{A}$:
\[
\left|  e_{1}\right\rangle =\left(
\begin{array}
[c]{c}
1\\
0\\
\vdots\\
0\\
\vdots\\
0
\end{array}
\right)  ,\quad \left|  e_{2}\right\rangle =\left(
\begin{array}
[c]{c}
0\\
1\\
\vdots\\
0\\
\vdots\\
0
\end{array}
\right)  , \dots , \left|  e_{i}\right\rangle =\left(
\begin{array}
[c]{c}
0\\
0\\
\vdots\\
1\\
\vdots\\
0
\end{array}
\right) , \dots , \left|  e_{n}\right\rangle =\left(
\begin{array}
[c]{c}
0\\
0\\
\vdots\\
0\\
\vdots\\
1
\end{array}
\right) \,,
\]
y $\left\{  \left|  u_{1}\right\rangle ,\left|  u_{2}\right\rangle, \dots , \left|  u_{i}\right\rangle, \dots , \left|  u_{n}\right\rangle \right\}$ la base de autovectores en la cual $\mathbf{\hat{A}}$ es diagonal. Por lo tanto $\mathbf{T}$ es la matriz de transformación de una base a la otra. Identificando columna a columna nos damos cuenta que las columnas de la matriz $\mathbf{T}$ son los autovectores de $\mathbf{A}$
\[
\left|  u_{i}\right\rangle =\sum_{j=1}^{n}T_{ij}\left|  e_{j}\right\rangle
\,\, \Rightarrow \,\, \left\langle e_{j}\right.  \left|  u_{i}\right\rangle
=\left\langle e_{j}\right.   \sum_{j=1}^{n}T_{ij}\left|  e_{j}
\right\rangle   \,,
\]
esto es:
\[
\left\langle e_{j}\right.  \left|  u_{i}\right\rangle =T_{ij}=\left(
\begin{array}
[c]{cccc}
u_{1}^{\left(  1\right)  } & u_{2}^{\left(  1\right)  } & \cdots &
u_{n}^{\left(  1\right)  }\\
u_{1}^{\left(  2\right)  } & u_{2}^{\left(  2\right)  } &  & u_{n}^{\left(
2\right)  }\\
\vdots &  & \ddots & \\
u_{1}^{\left(  n\right)  } & u_{2}^{\left(  n\right)  } &  & u_{n}^{\left(
n\right)  }
\end{array}
\right)  \,\, \Leftrightarrow \,\, \mathbf{T}^{\dagger}=\left(
\begin{array}
[c]{cccc}
u_{1}^{\left(  1\right)  } & u_{1}^{\left(  2\right)  } & \cdots &
u_{1}^{\left(  n\right)  }\\
u_{2}^{\left(  1\right)  } & u_{2}^{\left(  2\right)  } &  & u_{2}^{\left(
n\right)  }\\
\vdots &  & \ddots & \\
u_{n}^{\left(  1\right)  } & u_{n}^{\left(  1\right)  } &  & u_{n}^{\left(
n\right)  }
\end{array}
\right)  =\mathbf{T}^{-1} \,,
\]
donde hemos denotado $u_{i}^{\left( m\right)}$ la componente $m$ del vector $j$-esimo en la base $\left|  e_{i}\right\rangle $, con $i=1,\dots , n$. 

Por lo tanto, si los $n$ autovalores y autovectores de $\mathbf{A}$ son distintos y conocidos, $\mathbf{A}$ se dice diagonalizable. Si $\mathbf{A}$ es hermítica, $\mathbf{T}^{-1}=\mathbf{T}^{\dagger}$  es muy fácil construir la inversa de la matriz de transformación $\mathbf{T}$. Si los autovalores de $\mathbf{A}$ con degenerados, vale decir si el número de autovectores linealmente independientes es menor que $n$,  entonces $\mathbf{A}$ no es diagonalizable y no existe una matriz de transformacion $\mathbf{T}$ ($\mathbf{T}$ no tiene inversa) tal que $\mathbf{TAT}^{-1}=\mathbf{\hat{A}.}$

Ocupemonos  ahora del problema de la  solución de un  sistema de ecuaciones diferenciales no homogéneo de la forma:
\[
\mathbf{y}^{\prime}\left(x\right)  =\mathbf{Ay}\left(x\right)+\mathbf{g}\left(x\right) \,,
\]
con:
\[
\begin{array}
[c]{l}
\mathbf{A=}\left(
\begin{array}
[c]{cccc}
a_{11} & a_{12} & \cdots &  a_{1n}\\
a_{21} & a_{22} &  & a_{2n}\\
\vdots &  & \ddots & \\
a_{n1} & a_{n2} & \cdots &  a_{nn}
\end{array}
\right) \,, \qquad 
\mathbf{y} (x)  =\left(
\begin{array}
[c]{c}
y^{(1)}(x) \\
y^{(2)}(x)  \\
\vdots\\
y^{(n)}(x)
\end{array}
\right)\,, \qquad
\mathbf{g}\left(x\right)  =\left(
\begin{array}
[c]{c}
g^{\left(  1\right)  }\left(x\right)  \\
g^{\left(  2\right)  }\left(x\right)  \\
\vdots\\
g^{\left(  n\right)  }\left(x\right)
\end{array}
\right)
\end{array}
\]
donde $\mathbf{A}$ es una matriz constante y diagonalizable, $\mathbf{g}\left(x\right)$ contínua en el intervalo $\alpha\leq  x\leq\beta$. 

La solución de este problema pasa por encontrar los autovalores $\{ \lambda_i \}$ y autovectores $\{ \left|  u_{i}\right\rangle \}$ de $\mathbf{A}$, construir a partir de ellos la matriz $\mathbf{T}$ y su hermítica conjugada $\mathbf{T}^{-1}=\mathbf{T}^{\dagger}$,  y a partir de ella hacer el siguiente cambio de variable:
\[
\mathbf{y}\left(x\right)  =\mathbf{T z}\left(x\right)  \quad\Rightarrow\quad
\mathbf{Tz}^{\prime} =\mathbf{A\mathbf{T z}}+\mathbf{g} \quad\Rightarrow\quad
\mathbf{z}^{\prime} =\underset{\mathbf{\hat{A}}}{\underbrace{\mathbf{\mathbf{T}^{-1}A\mathbf{T}}}}\ 
\mathbf{\mathbf{z} }+\mathbf{\mathbf{T}^{-1}g} \,,
\]
por lo tanto
\[
\mathbf{z}^{\prime}  =\mathbf{\hat{A} z} +\mathbf{h} \,,
\]
donde
\[
\begin{array}
[c]{l}
\mathbf{\hat{A}=}\left(
\begin{array}
[c]{cccc}
\lambda_{1} & 0 & \cdots & 0\\
0 & \lambda_{2} &  & 0\\
\vdots &  & \ddots & \\
0 & 0 & \cdots & \lambda_{n}
\end{array}
\right)  \quad \text{y} \quad 
\mathbf{h} =\mathbf{\mathbf{T}^{-1}g} \,.
\end{array}
\]

Entonces, lo que tenemos ahora es un sistema de ecuaciones diferenciales desacoplado:
\[
z_{i}^{\prime}\left(x\right)  =\lambda_{i}z_{i}\left(x\right)+h_{i}\left(x\right)  \,.
\]

Por ejemplo, encontremos la solución general del siguiente sistema:
\begin{align*}
y'_1(x)  & = -2y_1(x)+ y_2(x) + 2e^{-x} \\
y'_2(x)  & = y_1(x)-2 y_2(x)+3x \,.
\end{align*}

En notación matricial:
\[
\mathbf{y}' = \left(
\begin{array}{rr}
    -2  & 1   \\
      1 &  -2 
\end{array} \right) \mathbf{y} + 
\left(\begin{array}{l}
    2e^{-x}    \\
       3x
\end{array} \right) 
\,\, \Rightarrow \,\, \mathbf{y}' = \mathbf{A}\mathbf{y} + \mathbf{g}(x) \,.
\]

Donde los autovalores y autovectores de $\mathbf{A}$ son
\[
\lambda_{1} = -3 \,, \quad
\xi_{1} = 
\left(
\begin{array}{r}
      1    \\
     -1   
\end{array} \right) \text{ y }  
\lambda_{2} = -1 \,, \quad
\xi_{2} = 
\left(
\begin{array}{r}
     1    \\
     1   
\end{array} \right) 
\,\, \Rightarrow \,\,  \mathbf{y}_h(x) = C_{1}\left(
\begin{array}{r}
      1    \\
     -1   
\end{array} \right) e^{-3x} + C_{2}\left(
\begin{array}{r}
     1    \\
     1   
\end{array} \right) e^{-x} \,,
\]
y donde $\mathbf{y}_h(x)$ es la solución general de la homogénea. 

Como $\mathbf{A}$ es real y simétrica, construimos la matriz $\mathbf{T}$ facilmente 
con los autovectores normalizados.  Esto es:
\[
\mathbf{T} = \frac{1}{\sqrt{2}}
\left(
\begin{array}{rr}
 1     & 1   \\
  -1    &   1
\end{array} 
\right) \,\, \Rightarrow \,\,
\mathbf{T}^{-1} = \frac{1}{\sqrt{2}}
\left(
\begin{array}{rr}
 1     & -1   \\
  1    &   1
\end{array} 
\right)\,.
\]

Ahora cambiando variables $\mathbf{y} = \mathbf{T}\mathbf{z}$  tendremos el siguiente sistema de ecuaciones
\[
\mathbf{z}^{\prime}  =\mathbf{\hat{A} z} +\mathbf{h} \,\, \Rightarrow \,\,
\left(
\begin{array}{c}
z'_1    \\
z'_2 
\end{array} 
\right) = 
\left(
\begin{array}{cc}
 -3    & 0   \\
  0    &   -1
\end{array} 
\right)
\left(
\begin{array}{c}
z_1    \\
z_2 
\end{array} 
\right)  + \frac{1}{\sqrt{2}}
\left(
\begin{array}{c}
 2e^{-x} -3x     \\
  2e^{-x} +3x   
\end{array} 
\right)\,,
\] 
con lo cual podemos escribir el  sistema desacoplado de ecuaciones lineales de primer orden
\[
z'_1+3z_{1} =\sqrt{2}e^{-x} - \frac{3}{\sqrt{2}}x \quad \text{y} \quad
z'_2 +3z_{2} =\sqrt{2}e^{-x} + \frac{3}{\sqrt{2}}x \,.
\]

Como ya sabemos, la solución es inmediata 
\[
z_{1}(x) = \frac{\sqrt{2}}{2}e^{-x} - \frac{3}{\sqrt{2}}\left(\frac{x}{3} - \frac{1}{9} \right) + C_{1}e^{-3x} 
\quad \text{y} \quad 
z_{2}(x) = \sqrt{2}xe^{-x} +  \frac{3}{\sqrt{2}}(x-1) + C_{2}e^{-x} 
\]
y devolviendo el cambio de variables tenemos que
\[
\mathbf{y} = \mathbf{T}\mathbf{z} \,\, \Rightarrow \,\,
\mathbf{y} =\frac{1}{\sqrt{2}}
\left( 
\begin{array}{c}
     z_{1} + z_{2}     \\
    -z_{1} + z_{2}    
\end{array} \right) \,.
\]

Vemos que
\begin{eqnarray*}
\frac{1}{\sqrt{2}}(z_{1} + z_{2} ) &=& 
\frac{C_1}{\sqrt{2}}e^{-3x} +\left(\frac{C_2}{\sqrt{2}} + \frac{1}{2} \right) e^{-x} + x -\frac{4}{3} + xe^{-x} \\
\frac{1}{\sqrt{2}}(-z_{1} + z_{2} ) &=&
-\frac{C_1}{\sqrt{2}}e^{-3x} +\left(\frac{C_2}{\sqrt{2}} - \frac{1}{2} \right) e^{-x} + 2x -\frac{5}{3}+ xe^{-x} \,.
\end{eqnarray*}

Si utilizamos unas nuevas constantes: $\mathcal{C}_1=\frac{C_1}{\sqrt{2}}$ y $\mathcal{C}_2=\frac{C_2}{\sqrt{2}} $, resulta que podemos escribir la solución de la forma:
\[
\mathbf{y} = \mathcal{C}_1
 \left(\begin{array}{r}
   1       \\
   -1     
\end{array} \right) e^{-3x} + 
\mathcal{C}_2\left(\begin{array}{c}
   1       \\
   1     
\end{array} \right) e^{-x} + \frac12
\left(
\begin{array}{r}
   1       \\
   -1     
\end{array} \right)e^{-x}  +
\left(\begin{array}{c}
   1       \\
    1     
\end{array} \right)xe^{-x}+
\left(\begin{array}{c}
   1       \\
    2     
\end{array} \right)x - \frac{1}{3}
\left(\begin{array}{c}
   4       \\
   5     
\end{array} \right) \,.
\]

De esta solución es fácil reconocer que los primeros dos términos se corresponden a la solución del sistema homogéneo y los restantes términos tienen que ver con una solución particular del sistema inhomogéneo.

\subsection{{\color{Fuchsia}Ejemplos}}

\subsection{{\color{red}Practicando con Maxima}}

\subsection{{\color{OliveGreen}Ejercicios}}

\begin{enumerate}

\item Encuentre un sistema de ecuaciones diferenciales de primer orden equivalente para 
las siguientes ecuaciones 

$
a) \,\, y'' -3x^2yy' =0 \qquad \qquad b) \,\, y'''-2x(y')^2+3xy''-xy =0
$

\item Encuentre la solución general de los siguientes sistemas de dos ecuaciones diferenciales

$
\begin{array}{lll}
a) \,\, y'_1 = 3y_1-2 y_2 \,,   & y'_2  = 2y_1-2 y_2  \\ \\
b) \,\, y'_1  = y_1-2 y_2 \,,     & y'_2  = 3y_1-4 y_2  \\ \\
c) \,\, y'_1  = 2y_1- y_2 \,,   & y'_2  = 3y_1-2 y_2  \\ \\
d) \,\, y'_1  = y_1 + y_2  \,,     & y'_2  = 4y_1-2 y_2
\end{array} 
$
\item Encuentre la solución general de los siguientes sistemas de tres ecuaciones diferenciales

$
\begin{array}{llll}
a) \,\, y'_1  = y_1 + y_2+2 y_3\,,   & y'_2  = y_1+2 y_2+y_3 \,, & y'_3 = 2y_1+ y_2+y_3 \\ \\
b) \,\, y'_1  = 3y_1 + 2y_2+4 y_3\,,   & y'_2  = 2y_1+2y_3 \,, & y'_3 = 4y_1+ 2y_2+3y_3 \\ \\
c) \,\, y'_1  = y_1 + y_2+ y_3\,,   & y'_2  = 2y_1+ y_2-y_3 \,, & y'_3 = -8y_1-5 y_2-3y_3 \\ \\
d) \,\, y'_1  = y_1 - y_2+4 y_3\,,   & y'_2  = 3y_1+2 y_2-y_3 \,, & y'_3 = 2y_1+ y_2-y_3 
\end{array} 
$

\item Encuentre la solución general de los siguientes sistemas de ecuaciones diferenciales

$
\begin{array}{llll}
a) \,\, y'_1 = 2y_1- y_2 +e^x \,,   & y'_2  = 3y_1-2 y_2 +x \\ \\
b) \,\, y'_1  = y_1 +\sqrt{3} y_2 +e^x \,,     & y'_2  = \sqrt{3}y_1- y_2  +\sqrt{3} e^x \\ \\
c) \,\, y'_1  = 2y_1- 5y_2 - \cos(x) \,,   & y'_2  = y_1-2 y_2 + \text{sen}(x)  \\ \\
d) \,\, y'_1  = y_1 + y_2 +e^{-2x} \,,     & y'_2  = 4y_1-2 y_2-2e^{x}
\end{array} 
$

\end{enumerate}

\section{Sistemas de ecuaciones diferenciales y el uso de operadores}

En clases anteriores  resolvimos algunos sistemas de ecuaciones diferenciales sacándole provecho a la notación matricial. Sin embrago, algunos sistemas son tan simples que tienen un método casi directo para su resolución, como podemos ver a continuación:

Dado el  siguiente sistema de ecuaciones diferenciales
\begin{eqnarray*}
\dot{x}  &=& 2e^{2t} \\
\dot{y}  &=& \frac{x^2-y}{t} \,.\quad t\neq 0\,.
\end{eqnarray*}

Rápidamente nos damos cuenta que la primera ecuación puede ser integrada de manera directa:
\[
\frac{\textrm{d} x}{ \textrm{d} t}  = 2e^{2t} \,\, \Rightarrow \,\, x(t)=e^{2t}+C_1
\]
al sustituir este resultado en la segunda ecuación:
\[
\frac{\textrm{d} y}{ \textrm{d} t} = \frac{\left(e^{2t}+C_1\right)^2-y}{t} 
\,\, \Rightarrow \,\,  
\frac{\textrm{d} y}{ \textrm{d} t}+\frac{y}{t}= \frac{e^{4t}+2C_1e^{2t}+C_1^2}{t}\,,
\]
esta última ecuación es lineal en $y$, por lo tanto la sabemos resolver:
\[
y(t)=\frac{ \frac14 e^{4t} + C_1 e^{2t}+C_1^2 t + C_2}{t}\,, \quad t\neq 0\,.
\]

Anteriormente  vimos algunas ventajas que aparecen por el hecho de utilizar la notación  de operadores para encontrar una solución de una ecuación diferencial lineal de orden $n$. Recordemos que una ecuación diferencial lineal de orden $n$ con coeficientes  constantes se podía escribir de la siguiente manera:
\begin{equation}
P(\mathbf{D})y = Q(x)\,.
\end{equation}
donde
\[
P(\mathbf{D})=a_0+a_1\mathbf{D}+a_2\mathbf{D}^2+ \cdots + a_n\mathbf{D}^n\,,\quad a_n\neq 0\,.
\]
con: $a_2, a_1, a_2, \dots ,a_n$ constantes.

En el caso de sistemas lineales de ecuaciones diferenciales podemos también hacer uso de esta notación:
\begin{eqnarray}
P_{11}(\mathbf{D}) y_1+ P_{12}(\mathbf{D}) y_2+P_{13}(\mathbf{D}) y_3+\cdots + 
P_{1n}(\mathbf{D}) y_n &=& Q_{1}\left(x\right)  \nonumber \\
P_{21}(\mathbf{D}) y_1+ P_{22}(\mathbf{D}) y_2+P_{23}(\mathbf{D}) y_3+\cdots + 
P_{2n}(\mathbf{D}) y_n &=& Q_{2}\left(x\right)  \nonumber  \\
  \vdots     \qquad  \qquad   \qquad  \qquad  &\vdots&  \nonumber \\
P_{n1}(\mathbf{D}) y_1+ P_{n2}(\mathbf{D}) y_2+P_{n3}(\mathbf{D}) y_3+\cdots + 
P_{nn}(\mathbf{D}) y_n &=& Q_{n}\left(x\right) \,.
\label{elsistema}
\end{eqnarray}

La solución del sistema (\ref{elsistema}) es el conjunto de funciones: $\{y_n(x)\}$, cada una de ellas definidas en un intervalo común $I$. 

Por ejemplo, para el siguiente sistema se tiene
\[
\begin{array}{rl}
2y'_1(x) +3 y_1(x) +5y'_2(x) -y_2(x)   & = e^{x} \\ 
\\ 
y'_1(x) - y_1(x) +3y'_2(x) +y_2(x)   & = \text{sen}(x) 
\end{array} 
\,\, \Rightarrow \,\, 
\begin{array}{rl}
(2\mathbf{D} +3) y_1 + (5\mathbf{D} -1) y_2   & = e^{x} \\ 
\\ 
(\mathbf{D} -3) y_1 + (3\mathbf{D} +1) y_2  & = \text{sen}(x) 
\end{array} 
\]

Notemos también que el sistema (\ref{elsistema}) es un caso más general  a los estudiados  anteriormente, que eran de la forma:
\[
\mathbf{y}'(x)=\mathbf{P}\left(x\right)  \mathbf{y}(x)+\mathbf{g}\left(x\right)  \,.
\]

Por cuestiones netamente didácticas nos detendremos en el caso $n=2$, entendiendo que los resultados aquí obtenidos pueden extrapolarse para cualquier valor de $n$.

Cuando $n=2$, tenemos entonces:
\begin{eqnarray}
P_{11}(\mathbf{D}) y_1+ P_{12}(\mathbf{D}) y_2 &=& Q_{1}\left(x\right)  \nonumber \\
P_{21}(\mathbf{D}) y_1+ P_{22}(\mathbf{D}) y_2 &=& Q_{2}\left(x\right) \,.
\label{elsisteman2}
\end{eqnarray}

Estos sistemas al resolverse para las funciones incógnitas deben contener un número apropiado de constantes y para tal fin existe un teorema que garantiza el número correcto de constantes que deben aparecer. 

\begin{mdframed}[linecolor=OliveGreen,linewidth=0.3mm]
\textbf{Teorema}: El número de constantes arbitrarias que deben aparecer en la solución 
del sistema (\ref{elsisteman2}) debe ser igual al orden de la siguiente expresión:
\begin{equation}
\Delta\equiv P_{11}(\mathbf{D}) P_{22}(\mathbf{D}) - P_{12}(\mathbf{D}) P_{21}(\mathbf{D}) 
\label{Delta}
\end{equation}
con: $\Delta \neq 0$.
\end{mdframed}

Si se da el caso que $\Delta = 0$, se dice que el sistema es {\it degenerado}. Notemos además que (\ref{Delta}) tiene la forma de un determinante. 

\begin{itemize}
\item {\bf Caso no degenerado: $\Delta \neq 0$} 

El sistema (\ref{elsisteman2})  puede ser tratado como un sistema de ecuaciones algebraico. Esto significa que podemos manipular las filas a nuestra conveniencia para obtener su solución o utilizar cualquier técnica para la resolución de sistemas de ecuaciones algebraicas  desarrollado en cursos anteriores.

Veamos un ejemplo:
\begin{eqnarray*}
2\dot{x} -x + \dot{y} + 4y &=& 1 \\
\dot{x} - \dot{y} &=& t-1 \,.
\end{eqnarray*}

Tal vez sea conveniente adaptar el problema a nuestra notación, es decir, hacemos los siguientes cambios:
$x(t)=y_1(x)$ y $y(t)=y_2(x)$. Por lo tanto:
\begin{eqnarray*}
2y'_1(x)-y_1(x) + y'_2(x) + 4y_1(x) &=& 1 \\
y'_1(x) - y'_2(x)&=& x-1 \,.
\end{eqnarray*}

En la notación del operador diferencial sería:
\begin{eqnarray*}
(2\mathbf{D} -1)y_1+  (\mathbf{D} +4)y_2&=& 1 \\
\mathbf{D} y_1-  \mathbf{D} y_2 &=& x-1 \,.
\end{eqnarray*}
Multipliquemos la primera ecuación por $\mathbf{D}$ y la segunda por $\mathbf{D} +4$: 
\begin{eqnarray*}
(2\mathbf{D}^2 -\mathbf{D})y_1 +  (\mathbf{D}^2 +4\mathbf{D})y_2&=& \mathbf{D}[1] \\
(\mathbf{D}^2 +4\mathbf{D})y_1-  (\mathbf{D}^2 +4\mathbf{D})y_2 &=& (\mathbf{D} +4)[x-1] \,.
\end{eqnarray*}

Luego las sumamos para obtener:
\[
(3\mathbf{D}^2 +3\mathbf{D})y_1= 0 + \mathbf{D}[x-1] +4(x-1)=  1 + 4x-4= 4x-3\,,
\]
esto significa que debemos resolver la siguiente ecuación 
\[
3y''_1 +3y'_1= 4x-3\,,
\]
con la ayuda de algunos de los métodos anteriormente vistos se obtiene la respectiva solución:
\[
y_1(x)= C_1+C_2e^{-x}+ \frac23 x^2- \frac73 x \,.
\]

Al sustituir $y_1(x)$ en la segunda ecuación del sistema resulta:
\begin{eqnarray*}
\mathbf{D} \left[ C_1+C_2e^{-x}+ \frac23 x^2- \frac73 x \right]-  \mathbf{D} y_2&=&x-1 \\
-C_2e^{-x}+ \frac43 x- \frac73   -  \mathbf{D} y_2&=&x-1 \\
-C_2e^{-x}+ \frac13 x- \frac43   -  \mathbf{D} y_2&=&0 \,,
\end{eqnarray*}
por lo tanto:
\[
y'_2= -C_2e^{-x}+ \frac13 x- \frac43 \quad \Rightarrow \quad 
y_2(x) =  C_2e^{-x}+ \frac16 x^2- \frac43 x + C_3\,.
\]

Ahora podemos estudiar el tema del número de constantes que deben aparecer. Del teorema anterior vemos que el determinate 
\begin{equation*}
\Delta= (2\mathbf{D} -1) (- \mathbf{D}) - (\mathbf{D})  (\mathbf{D} +4) = -3\mathbf{D}^2-3\mathbf{D}\,,
\label{condicion}
\end{equation*}
es de orden 2. Por lo tanto, según el teorema antes mencionado deben existir únicamente dos constantes. Esto significa que tenemos una constante demás. Podemos hallar una relación entre las constantes sustituyendo las dos soluciones encontradas en la primera ecuación del sistema, recordemos la la segunda ecuación ya fue utilizada para encontrar $y_2(x)$. Esto es:
\begin{eqnarray*}
(2\mathbf{D} -1)\left[  C_1+C_2e^{-x}+ \frac23 x^2- \frac73 x\right]+  (\mathbf{D} +4)\left[  C_2e^{-x}+ \frac16 x^2- \frac43 x + C_3\right] &=& 1 \\
-6-C_1+4C_3 = 1 \,\, \Rightarrow \,\, C_3&=&\frac{C_1+7}{4} \,.
\end{eqnarray*}

Por lo tanto, la solución al sistema será:
\begin{eqnarray*}
y_1(x) &=&  C_1+C_2e^{-x}+ \frac23 x^2- \frac73 x \\
y_2(x) &=&  C_2e^{-x}+ \frac16 x^2- \frac43 x + \frac{C_1+7}{4}\,.
\end{eqnarray*}


\item {\bf Caso degenerado: $\Delta =0$}

Como puede suceder para los sistemas algebraicos el sistema de ecuaciones puede ser degenerado, es decir,  podrá tener infinitas soluciones o no tener solución, por ejemplo, el sistema:
\begin{eqnarray*}
2x+3y&=& 5 \\
2x+3y&= &  7 \,,
\end{eqnarray*}
no tiene solución. Y el sistema 
\begin{eqnarray*}
2x+3y&=& 0 \\
4x+6y&= &0 \,,
\end{eqnarray*}
tiene infinitas soluciones. En ambos casos, el determinante conformado por los coeficientes de $x$ y de $y$ es cero. Notemos también que para el primer sistema, si despejamos $y$ de la segunda  ecuación
\[
y=   \frac{7-2x}{3}\,,
\]
y la sustituimos en la primera resulta:
 \[
 2x+3\left[  \frac{7-2x}{3} \right]= 5 \quad \Rightarrow \quad 7  = 5\,,
 \]
no existe solución cuando el sistema no se reduce a una igualdad.

Si hacemos lo mismo con el segundo sistema, despejamos $y$ en una 
\[
y=  - \frac{2x}{3}\,,
\]
y la sustituimos en la otra
 \[
2x+3\left[  - \frac{2x}{3} \right]= 0 \,\, \Rightarrow \,\, 0  = 0 \,.
 \] 
Existen infinitas soluciones si el sistema se reduce a una igualdad del tipo $0=0$. 

Con los sistemas de ecuaciones diferenciales pasa lo mismo. Veamos un par de ejemplos.
 
El sistema
 \begin{eqnarray*}
\mathbf{D}y_1 -  \mathbf{D}y_2&=& x \\
\mathbf{D}y_1-  \mathbf{D}y_2&= &  x^2 \,.
\end{eqnarray*}
 es degenerado porque $-\mathbf{D}^2-(-\mathbf{D}^2) = 0$. Si despejamos $\mathbf{D}y_1$ de la segunda ecuación 
 \[
 \mathbf{D}y_1=  \mathbf{D}y_2+   x^2 \,,
 \]
 y sustituimos en la primera:
 \[
 \mathbf{D}y_2+   x^2  -  \mathbf{D}y_2= x \quad \Rightarrow \quad x^2=x\,.
 \]
 este sistema no tiene solución.

\end{itemize}

Volvamos al caso no degenerado. Como hemos mencionado el hecho de usar los operadores hace que el sistema puede ser tratado de manera similar al de un sistema algebraico, y por lo tanto, podemos utilizar  cualquiera de los métodos para la resolución de sistemas algebraicos. 

Consideremos el siguiente sistema  de ecuaciones lineales:
\begin{eqnarray}
P_{11}(\mathbf{D}) y_1+ P_{12}(\mathbf{D}) y_2+P_{13}(\mathbf{D}) y_3 &=&Q_{1}\left(x\right)  \nonumber \\
P_{21}(\mathbf{D}) y_1+ P_{22}(\mathbf{D}) y_2+P_{23}(\mathbf{D}) y_3&=& Q_{2}\left(x\right)  \nonumber  \\
P_{31}(\mathbf{D}) y_1+ P_{32}(\mathbf{D}) y_2+P_{33}(\mathbf{D}) y_3 &=& Q_{3}\left(x\right) \,.
\label{elsistema3x3}
\end{eqnarray}

El determinante que podemos asociar a éste sistema es:
\begin{eqnarray*}
\Delta &=& P_{11}(\mathbf{D}) P_{22}(\mathbf{D}) P_{33}(\mathbf{D}) +
 P_{21}(\mathbf{D}) P_{32}(\mathbf{D}) P_{13}(\mathbf{D})+
 P_{12}(\mathbf{D}) P_{23}(\mathbf{D}) P_{13}(\mathbf{D}) \\
 &-&
 P_{31}(\mathbf{D}) P_{22}(\mathbf{D}) P_{13}(\mathbf{D}) -
 P_{32}(\mathbf{D}) P_{23}(\mathbf{D}) P_{11}(\mathbf{D})-
 P_{21}(\mathbf{D}) P_{12}(\mathbf{D}) P_{33}(\mathbf{D}) 
\end{eqnarray*}

La manera usual de resolver este sistema es eliminar algunas de las variables, digamos $y_3 $, de manera que nos queda un sistema reducido a dos ecuaciones, digamos:
\begin{eqnarray}
\tilde{P}_{11}(\mathbf{D}) y_1+ \tilde{P}_{12}(\mathbf{D}) y_2 &=&\tilde{Q}_{1}\left(x\right)  \nonumber \\
\tilde{P}_{21}(\mathbf{D}) y_1+ \tilde{P}_{22}(\mathbf{D}) y_2&=& \tilde{Q}_{2}\left(x\right)\,, 
\label{elsistema3x3a}
\end{eqnarray}

Si de éste sistema eliminamos $y_2$, entonces lo que queda es una solo ecuación
\begin{equation}
\hat{P}_{11}(\mathbf{D}) y_1=\hat{Q}_{1}\left(x\right) \,,
\label{elsistema3x3b}
\end{equation}
la cual podemos resolver para $y_1$. Al sustituir este valor en cualquiera de las ecuaciones (\ref{elsistema3x3a}) se obtiene $y_2$. Finalmente, la sustitución de $y_1$ y $y_2$ en cualquiera de las ecuaciones de  (\ref{elsistema3x3}) permite obtener $y_3$. El número de constantes quedará determinado por el oden de $\Delta$.
 
Otra manera de proceder es manipular el sistema (\ref{elsistema3x3})  de manera tal que se obtenga un sistema equivalente triangular, es decir, de la forma:
\begin{eqnarray}
\tilde{P}_{11}(\mathbf{D}) y_1 &=&\tilde{Q}_{1}\left(x\right)  \nonumber \\
\tilde{P}_{21}(\mathbf{D}) y_1+ \tilde{P}_{22}(\mathbf{D}) y_2&=& \tilde{Q}_{2}\left(x\right)  \nonumber  \\
\tilde{P}_{31}(\mathbf{D}) y_1+ \tilde{P}_{32}(\mathbf{D}) y_2+\tilde{P}_{33}(\mathbf{D}) y_3 &=& \tilde{Q}_{3}\left(x\right) \,.
\label{elsistema3x3tri}
\end{eqnarray}

Aquí, las soluciones se van obteniendo desde la primera ecuación hasta la última. Es bueno resaltar el hecho de que las soluciones obtenidas utilizando un sistema equivalente triangular contienen el número correcto de constantes requerido por el sistema. Entonces, para obtener un sistema equivalente triangular procedemos de la siguiente manera: decidimos dejar una de las ecuaciones sin intervenir y manipulamos las otras dos, repetimos este procedimiento  las veces que sean necesarias hasta obtener el sistema deseado.

Por ejemplo,  resolvamos el sistema
\begin{eqnarray*}
\dot{x} -2x + y-z&=& t \quad \quad  \quad \quad  (\mathbf{D} -2)y_1+  y_2  - y_3 = x\\
-x + 2\dot{y} +y +2z &=& 1 \,\, \Rightarrow \,\,  -y_1+(2\mathbf{D} +1)y_2  + 2y_3=1 \\
2x +6y  +\dot{z}  &=& 0 \quad \quad  \quad  \quad  2y_1+6y_2+\mathbf{D}y_3=0\,.
\end{eqnarray*}

\begin{itemize}
\item Retenemos la primer ecuación del sistema.
\item Creamos un nuevo sistema multiplicando la primera ecuación por $2$ y sumándola con la segunda, para de esta manera eliminar $y_3$. Con el mismo fin, multiplicamos
la primera por $\mathbf{D}$ y la sumamos con la tercera. Con esto obtenemos:
\begin{eqnarray*}
(\mathbf{D} -2)y_1+  y_2  - y_3 &=& x\\
(\mathbf{D} -5)y_1+(2\mathbf{D} +3)y_2 &=& 2x+1 \\
(\mathbf{D}^2- 2\mathbf{D}+2)y_1+(\mathbf{D} +6)y_2 &=&1
\end{eqnarray*}
\item Podemos retener la primera y tercera ecuación y cambiamos la segunda. Entonces multiplicamos la tercera por $-2$ y la sumamos con la segunda:
\begin{eqnarray*}
(\mathbf{D} -2)y_1+  y_2  - y_3 &=& x\\
(-2\mathbf{D}^2 +6\mathbf{D}-9)y_1- 9y_2 &=& 2x-1 \\
(\mathbf{D}^2- 2\mathbf{D}+2)y_1+(\mathbf{D} +6)y_2 &=&1
\end{eqnarray*}
\item Retenemos la primera y segunda ecuación y cambiamos la tercera. Lo podemos hacer multiplicando la segunda por $(\mathbf{D}+6)/9$ y luego se suma con la tercera:
\begin{eqnarray*}
(\mathbf{D} -2)y_1+  y_2  - y_3 &=& x\\
(-2\mathbf{D}^2 +6\mathbf{D}-9)y_1- 9y_2 &=& 2x-1 \\
(-\mathbf{D}^3+3\mathbf{D}^2 +9\mathbf{D}-36)y_1 &=&12x+5
\end{eqnarray*}
\end{itemize}

Por lo tanto, ya se puede integrar la última ecuación:
\[
y_1(x)=\frac{C_1}{3}\,{{e}^{3\,x}}  - \frac{2C_2}{3}\,{{\rm e}^{-\frac{3}{2}x}}+ \frac{2}{3}{x}^{2}+
{\frac {37}{9}}\,x+C_3 \,.
\]

Al sustituir $y_1(x)$ en la segunda ecuación resulta que simplemente queda despejar $y_2(x)$
\begin{eqnarray*}
(-2\mathbf{D}^2 +6\mathbf{D}-9)\left[\frac{C_1}{3}\,{{e}^{3\,x}}  - \frac{2C_2}{3}\,{{\rm e}^{-\frac{3}{2}x}}+ \frac{2}{3}{x}^{2}+{\frac {37}{9}}\,x+C_3\right]- 9y_2 &=& 2x-1\\
- 3C_1{{e}^{3\,x}}+15C_2{{e}^{-\frac{3}{2}x}} - 6\,{x}^{2} - 29x +22 -9C_3-9y_2&=& 2x-1\,,
\end{eqnarray*}
es decir:
\[
y_2(x)= -\frac{C_1}{3}e^{3x}+ \frac{5C_2}{3}e^{-\frac{3}{2}x}-\frac23{x}^{2}
-{\frac {31}{9}}\,x+{\frac {23}{9}}-C_3 \,.
\]

Queda por último sustituir $y_1(x)$ y $y_2(x)$ en la primera ecuación y despejar $y_3(x)$:
\begin{eqnarray*}
(\mathbf{D} -2)\left[ \frac{C_1}{3}\,{{e}^{3\,x}}  - \frac{2C_2}{3}\,{{\rm e}^{-\frac{3}{2}x}}+ \frac{2}{3}{x}^{2}+{\frac {37}{9}}\,x+C_3\right] &+& \\
\left[ -\frac{C_1}{3}e^{3x}+ \frac{5C_2}{3}e^{-\frac{3}{2}x}-\frac23{x}^{2}
-{\frac {31}{9}}\,x+{\frac {23}{9}}-C_3\right]  - y_3 &=&x \\
4C_2e^{-\frac{3}{2}x}  -2\,{x}^{2} -{\frac {31}{3}}\,x  + {\frac {20}{3}}- 3C_3-y_3 &=&x\,,
\end{eqnarray*}

por lo tanto:
\[
y_3(x)=4C_2e^{-\frac{3}{2}x}  -2\,{x}^{2} -{\frac {34}{3}}\,x  
+ {\frac {20}{3}}- 3C_3\,.
\]

No es necesario investigar sobre el número de constantes, en todo caso, y solo por curiosidad se puede ver que el determinante del sistema, al igual que para el sistema triangular, es de orden 3:
\[
\Delta= \left[ \begin {array}{ccc} \mathbf{D}-2&1&-1\\ \noalign{\medskip}-1&2\,\mathbf{D}+1&2
\\ \noalign{\medskip}2&6&\mathbf{D}
\end {array} \right] = 2\,\mathbf{D}^{3}-3\,\mathbf{D}^{2}-9\mathbf{D}+36\,.
\]

\subsection{{\color{Fuchsia}Ejemplos}}

\subsection{{\color{red}Practicando con Maxima}}

\subsection{{\color{OliveGreen}Ejercicios}}
\begin{enumerate}
\item Resuelva el sistema
\begin{eqnarray*}
(\mathbf{D} +3)y_1+  (\mathbf{D} +1)y_2&=& e^{x} \\
(\mathbf{D} +1)y_1+  (\mathbf{D} -1)y_2&= &  x \,.
\end{eqnarray*}
En este caso $\Delta$ es de orden cero y no deben aparecer constantes arbitrarias.

\item Demuestre que el siguiente sistema es degenerado y tiene infinitas soluciones
\begin{eqnarray*}
\mathbf{D}y_1 -  \mathbf{D}y_2&=& x \\
4\mathbf{D}y_1-  4\mathbf{D}y_2&= & 4 x \,.
\end{eqnarray*}

\end{enumerate}



\section{Sistemas  y la transformada de Laplace}

A diferencia del método anterior, el método de transformadas de Laplace solo se puede aplicar si además del sistema se suministran el conjunto completo de condiciones iniciales. Esto significa que la solución particular obtenida  ya satisface las condiciones iniciales y no necesitamos evaluar las constantes arbitrarias que puedan resultar.

Como en capítulos anteriores resolvimos algunas ecuaciones diferenciales utilizando transformadas de Laplace, podemos pasar directamente a un ejemplo para ver como se aplica el método cuando se tienen sistemas de ecuaciones diferenciales ( "!No necesariamente de primer orden!). 

Veamos el ejemplo de resolver el sistema 
\begin{eqnarray*}
\ddot{x} -4x + \dot{y}&=& 0 \\
-4\dot{x}  + \ddot{y} +2y &=& 0 \quad \text{con:} \quad x(0)=0\,, \dot{x}(0)=1\,, y(0)=-1\,, \dot{y}(0)=2\,.
\end{eqnarray*}
En este caso el sistema consiste de dos ecuaciones con dos incógnitas, pero debe quedar claro que el método se puede extender para sistemas con un número mayor de ecuaciones.

Como vimos anteriormente, utilizando la notación de las transformadas de Laplace el sistema se puede escribir de la siguiente manera.
\begin{eqnarray*}
\mathcal{L} \left[y_1'' \right] -4\mathcal{L} \left[y_1\right]  + \mathcal{L} \left[y'_2\right] &=& 0 \\
-4\mathcal{L} \left[y'_1\right]  + \mathcal{L} \left[y''_2\right]  +2\mathcal{L} \left[y_2\right]  &=& 0 
\end{eqnarray*}

Donde también, hemos rebautizado las funciones de la siguiente manera: $y_1(x)=x(t)$ y $y_2(x)=y(t)$.

Revisando las notas de las clases correspondientes a las transformadas de Laplace, podemos ver que el sistema anterior queda de la siguiente forma:
\begin{eqnarray*}
s^2\mathcal{L} \left[y_1 \right]-y'_1(0) -s y_1(0)-4\mathcal{L} \left[y_1\right]  + 
s\mathcal{L} \left[y_2\right] -y_2(0) &=& 0 \\
-4s\mathcal{L} \left[y_1 \right]+4y_1(0) + s^2\mathcal{L} \left[y_2\right]  - y'_2(0)-sy_2(0)+
2\mathcal{L} \left[y_2\right]  &=& 0 
\end{eqnarray*}
al sustituir los respectivos valores para las condiciones iniciales y factorizando,  resulta:
\begin{eqnarray*}
(s^2-4)\mathcal{L} \left[y_1 \right]  + s\mathcal{L} \left[y_2\right]  &=& 0 \label{ecu1} \\
-4s\mathcal{L} \left[y_1 \right]+ (s^2+2) \mathcal{L}\left[y_2\right]  - 2+s  &=& 0 \label{ecu2} 
\end{eqnarray*}

Este último sistema puede ser tratado como un sistema algebraico para $\mathcal{L} \left[y_1 \right]$ y $\mathcal{L} \left[y_2 \right]$. Si multiplicamos la primera por $4s$, la segunda por $s^2-4$ y luego las sumamos eliminamos $\mathcal{L} \left[y_1 \right]$, resulta:
\[
(s^4+2s^2-8)\mathcal{L} \left[y_2 \right]=-s^3+2s^2+4s-8 \,,
\]
despejando $\mathcal{L} \left[y_2 \right]$:
\[
\mathcal{L} \left[y_2 \right]=\frac{-s^3+2s^2+4s-8}{s^4+2s^2-8}= \frac{-s^3+2s^2+4s-8}{(s^2+4)(s^2-2)}=
\frac16\left[\frac{1+\sqrt{2}}{s+\sqrt{2}} + \frac{1-\sqrt{2}}{s-\sqrt{2}} -\frac{8(s-2)}{s^2+4}  \right]\,.
\]

Ahora debemos  buscar en nuestra tablita de transformadas de Laplace, para hallar las transformadas inversas:
\begin{eqnarray*}
\mathcal{L} \left[(1+\sqrt{2})e^{-\sqrt{2}x} \right]  &=&  \frac{1+\sqrt{2}}{s+\sqrt{2}}  \\
\mathcal{L} \left[(1-\sqrt{2})e^{\sqrt{2}x}  \right]  &=&  \frac{1-\sqrt{2}}{s-\sqrt{2}} \\
\mathcal{L} \left[-8\cos(2x) \right]   &=&  -8 \left[\frac{s}{s^2+2^2}\right] \\
\mathcal{L} \left[ 8 \ \text{sen}(2x) \right]  &=&   8 \left[ \frac{2}{s^2+2^2} \right] 
\end{eqnarray*}
por lo tanto:
\[
y_2(x)=\frac16\left[ (1+\sqrt{2})e^{-\sqrt{2}x} + (1-\sqrt{2})e^{\sqrt{2}x}  -8\cos(2x) + 8 \ \text{sen}(2x)\right]\,.
\]

Para calcular $y_1(x)$, podemos sustituir $\mathcal{L} \left[y_2 \right]$ en cualquiera de las ecuaciones  (\ref{ecu1}) - (\ref{ecu2}) y resolver para $\mathcal{L} \left[y_1 \right]$:
\[
(s^2-4)\mathcal{L} \left[y_1 \right]  + s\mathcal{L} \left[y_2\right]  = 0 \,\, \Rightarrow \,\,
(s^2-4)\mathcal{L} \left[y_1 \right]  + s\left[\frac{-s^3+2s^2+4s-8}{(s^2+4)(s^2-2)}\right]= 0 \,,
\]
esto es:
\[
\mathcal{L} \left[y_1 \right]  = \frac{s(s-2)}{(s^2+4)(s^2-2)}=-\frac{1}{12}\left[ \frac{2-\sqrt{2}}{s-\sqrt{2}} + \frac{2+\sqrt{2}}{s+\sqrt{2}} -4\left(\frac{s+2}{s^2+4}\right) \right]\,.
\]

Nuevamente buscando en las tablas de transformadas de Laplace, término por término, se llega finalmente al siguiente resulado:
\[
y_1(x)=-\frac{1}{12}\left[ (2-\sqrt{2})e^{\sqrt{2}x} + (2+\sqrt{2})e^{-\sqrt{2}x}  -4\cos(2x) -4 \ \text{sen}(2x)\right]\,.
\]

\paragraph{Ejercicios} 
\begin{enumerate}
\item Resuelva cada uno de los siguientes sistemas de ecuaciones diferenciales

\[
\begin{array}{ll}
a) \,\, \dot{x} = -x^2 \,,   & \dot{y} = -y   \\ \\
b) \,\,  \dot{x} = 3e^{-t} \,,   & \dot{y} = x+y   \\ \\
c) \,\, \dot{x} = 2t \,,   & \dot{y} = 3x+2t \,, \qquad \dot{z} = x+4y+t \\ \\
d) \,\, \dot{x} = 3x+2e^{3t} \,,   & \dot{x}+\dot{y} -3y= \text{sen}(2t) \\ \\
e) \,\, \ddot{x}+4x = 3 \ \text{sen}(t)  \,,   & \dot{x}-\ddot{y} +y= 2 \cos(t) \\ \\
f) \,\, \ddot{x}-4x-2\dot{y}+y = t  \,,   & 2\dot{x}+x+\ddot{y} +y= 0
\end{array} 
\]
\item Verifique que los siguientes sistemas son degenerados. Encuentre las soluciones si existen

$
\begin{array}{ll}
a) \,\, \mathbf{D}x+2\mathbf{D}y=e^t \,, & \mathbf{D}x+2\mathbf{D}y=t  \\ \\
b) \,\,  \mathbf{D}x-\mathbf{D}y=e^t \,,   & 3\mathbf{D}x -3\mathbf{D}y=3e^{t}  \\ \\
c) \,\,  (\mathbf{D}^2-1)x + (\mathbf{D}^2-1)y=0\,,   & (\mathbf{D}^2+4)x + (\mathbf{D}^2+4)y=0  \\ \\
d) \,\,  (\mathbf{D}-2)x + (\mathbf{D}-2)y=t\,,   & (\mathbf{D}+3)x + (\mathbf{D}+3)y=t   
\end{array} 
$

\item Resuelva  los siguientes sistemas de ecuaciones diferenciales

$
\begin{array}{llll}
a) \,\, (\mathbf{D}-1)x=0\,,   & -x +( \mathbf{D}-3)y=0  \,, &  -x+y +( \mathbf{D}-2)z=0 \\ \\
b) \,\, (\mathbf{D}-1)x=0\,,   & 3x +2( \mathbf{D}+1)y=0  \,, &  2y +(2 \mathbf{D}-3)z=0   \\ \\
c) \,\, (\mathbf{D}-2)x=0\,,   & -3x +( \mathbf{D}+2)y=0  \,, &  -2y +( \mathbf{D}-3)z=0  \\ \\
d) \,\, \mathbf{D}x - y + z=0\,,  & -x +( \mathbf{D}-1)y=0  \,, &  -x+( \mathbf{D}-1)z=0 
\end{array} 
$
\item Resuelva  los siguientes sistemas utilizando transformadas de Laplace

$
\begin{array}{lll} 
a) \,\, \dot{x} -y= t \,,   & x-\dot{y} = 1\,,                                   & x(0)=2\,, y(0)=2 \\ \\
b) \,\,  3\dot{x} +3x +2y= e^{t} \,,   & 4x-3\dot{y} +3y= 3t \,, & x(0)=1\,, y(0)=-1 \\ \\
c) \,\, \dot{x} +\dot{y}-4y= 1 \,,   & x+\dot{y} -3y = t^2\,,        & x(0)=2\,, y(0)=-2 \\ \\
d) \,\, \ddot{x}-\dot{y} =1-t \,,   & \dot{x}+2\dot{y} = 4e^t + x& x(0)=0\,, y(0)=0\,,x'(0)=1
\end{array} 
$
\end{enumerate}


\subsection{{\color{Fuchsia}Ejemplos}}

\subsection{{\color{red}Practicando con Maxima}}

\subsection{{\color{OliveGreen}Ejercicios}}


